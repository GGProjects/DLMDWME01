---
title: "Exploratory Analysis: StandyBy Data"
author: "Georg Grunsky"
editor: visual
bibliography: references.bib
---

Dieses Dokument beschreibt die vorbereitenden Abschnitte Prüfung der Datenqualität und Explorative Datenanalyse für den bestehenden Use Case. Die Bereiche Datenaufbereitung und Modellierung werden in den jeweiligen Modellverzeichnissen behandelt. [@pak_fallstudie_2022]

# Feststellen der Datenqualität

## Datensätze einlesen

Die Daten werden in zwei Dateien bereitgestellt: ***sickness_table.csv*** und ***sickness_table.xlsx***. Augenscheinlich handelt es sich dabei um den selben Datensatz,was jedoch eingangs noch zu überprüfen ist.

```{r}
#| echo: true
#| message: false
#| warning: false

require(readr)
path_to_samples <- "../00_sample_data/"
sickness_csv <- read_csv(paste0(path_to_samples,"01_raw/sickness_table.csv"), 
    col_types = cols(date = col_datetime(format = "%Y-%m-%d")))
head(sickness_csv)
```

```{r}
#| echo: true
#| message: false
#| warning: false

require(readxl)
sickness_xls <- read_excel(paste0(path_to_samples,"01_raw/sickness_table.xlsx"), 
    col_types = c("numeric", "date", "numeric", 
        "numeric", "numeric", "numeric", "numeric", 
        "numeric"))
head(sickness_xls)
```

## Datensätze vergleichen

```{r}
#| echo: true
#| message: false
#| warning: false

identical(sickness_csv, sickness_xls)
```

Die Überprüfung mittels *identical* besagt, dass die Datensätze nich identisch sind. Die in den jeweiligen Daten-Dictionaries beschriebenen Datenstrukturen lassen jedoch schon darauf schließen. Eine Summary der Wertebereiche der vorliegenden Daten schafft mehr Klarheit.

## Daten Summary

### sickness_csv

```{r}
#| echo: true
#| message: false
#| warning: false

summary(sickness_csv)
```

### sickness_xls

```{r}
#| echo: true
#| message: false
#| warning: false

summary(sickness_xls)
```

Gemäß den angezeigten Wertebereichen handelt es sich tatsächlich um die gleichen Datensätze.

Anhand der .csv Datei wird noch überprüft ob der Datensatz fehlende Werte beinhaltet, bevor mit der weiteren Datenexploration fortgefahren wird.

## NAs und "Missing Values"

```{r}
#| echo: true
#| message: false
#| warning: false

alldays <- seq(from = as.Date("2016-04-01"),
               to = as.Date("2019-05-27"),
               by = 1)

if (identical(alldays, as.Date(sickness_csv$date))) print("no missing dates") else print("you have to deal w/ missing dates")

if (!anyNA.data.frame(sickness_csv)) print("no missing values") else print("you have to deal w/ missing values")
```

In dieser Zeitreihe haben wir weder mit fehlenden Zeitwerten noch NAs in den Datenpunkten umzugehen. Die Prüfung der Datenqualität wird somit abgeschlossen.

## Zusammenfassung

1.  Die bereitgestellten Datensätze scheinen identisch zu sein. Es wird nur mit der .csv Datei weitergearbeitet.

```{r}
#| message: false
#| warning: false
#| include: false

rm(sickness_xls,
   path_to_samples,
   alldays)
```

2.  Es gibt keine fehlenden Zeitwerte und/oder NAs in den Datenpunkten
3.  Der bisherige Fixwert von 90 Bereitschaftspersonen (*n_sby*) scheint in den meisten Fällen im Vergleich zu *sby_need* zu hoch zu sein. Es gibt jedoch auf Tage wo mehr als 90 Personen gebraucht werden.
4.  Die Zeitreihe behandelt den Zeitraum von 2016-04-01 bis 2019-05-27. Eine Periode von drei Jahren vor der COVID Pandemie. Es ist davon auszugehen, dass COVID die aktuellen Zahlen verändert hat. Denoch hilft eine erfolgreiche Umsetzung einer Vorhersage auf den Testdaten, das Projekt mit aktuellen Daten voranzutreiben und zukünftig Bereitschaftskosten sparen zu können.
5.  Die Anzahl der Anrufe und die Anzahl des krankgemeldeten Personals scheint ähnliche Proportionen aufzuweisen, nur um etwa den Faktor 100 kleiner.

# Explorative Datenanalyse

```{r}
#| label: load packages
#| message: false
#| warning: false
#| include: false

require(dplyr)
require(fpp3)
require(plotly)
require(ggpubr)
```

@hyndman_forecasting_2021 bietet von der Exploration bis zur Modellierung einen sehr ausführlichen Anhalt für die Arbeit mit Zeitreihendaten. Ein weiteres R-Package, das gute Werkzeuge für die explorative Analyse aber auch für die Erstellung von Models anbietet ist *caret*. Das Paket eignet sich zwar weniger gut für Zeitreihendaten, aus der Dokumentation alleine kann aber bereits viel gelernt werden. [@kuhn_caret_2019].

## Merkmalsübersicht

Datenplots unterstützen in der Feststellung von Abhängigkeiten und Verteilungen. Die erste Spalte (*id*), die bisher konstante Einteilung des Bereitschaftspersonals (*n_sby*), sowie die Anzahl der zusätzlich benötigten Fahrer:innen (*dafted*) werden, zur besseren Übersicht, hierbei bereits ausgeblendet. Da es sich um Zeitreihendaten handelt, wird der Datensatz auch in ein entsprechendes Objekt konvertiert.

```{r}
#| echo: true
#| message: false
#| warning: false

ts_sby <- sickness_csv %>%
  select(-c("...1", "n_sby", "dafted")) %>%
  mutate(date = as.Date(date)) %>%
  as_tsibble(index = date)

ts_sby %>%
  GGally::ggpairs()
```

*sby_need* (die Zielvariable) korreliert augenscheinlich am meisten mit der Anzahl der Notfallanrufe (*calls*). Hier liegt, ab einer gewissen Anzahl an *calls* nahezu eine lineare Korrelation vor. Das klingt durchaus plausibel. Die vermutete Saisonalität ist in der Übersicht der Variablen *sby_need*, *calls* und *n_sick* (der Anzahl der krankgemeldeten Bereitschaftsfahrer:innen), mit dem menschlichen Auge, gut zu erkennen. und wirkt bei dem Merkmal *calls* am stabilsten.

Das Merkmal *n_duty* (die Anzahl der diensthabenden Bereitschaftsfahrer:innen) weist nur drei unterschiedliche Werte auf, die ausschließlich eine Abhängigkeit zum Datum haben. Hierbei wurde die Anzahl der Diensthabenden jedes Jahr zum ersten Januar um 100 Personen erhöht. Am 01.01.2019 ist dies jedoch nicht geschehen. Dieser Umstand muss vermutlich gesondert mit den Entscheidungsträgern besprochen und ggf. nachgezogen werden.

*n_sick* zeigt zwar die angesprochene Saisonalität, weist, aufgrund der o.a. Grafik, aber nur eine geringe Korrelation zur Zielvariablen auf. Es scheint plausibel, dass eine höhere Anzahl an Krankenständen, bei gleichbleibenden oder steigenden Notfällen zu einem höheren Bedarf an Bereitschaftspersonal führt. Möglicherweise unterstützt die Kombination dieser beiden Merkmale eine erfolgsversprechende Vorhersage.

Für die Vorhersage des Merkmals *sby_need* gibt es zu diesem Zeitpunkt daher fünf mögliche Ansatzpunkte.

1.  Die direkte Vorhersage aufgrund des Datum und der eigenen Saisonalität
2.  Eine indirekte Vorhersage aufgrund der Saisonalität des Merkmals *calls* und der, ab einem gewissen Wert, nahezu linear anzunehmenden Korrelation mit *sby_need*. Letztere zeigt jedoch "drei Liniaritäten" und ist wahrscheinlich durch *n_duty* beeinflusst.
3.  Wie in Punkt 2., nur dass zusätzlich eine jährliche Steigerung von *n_duty* berücksichtigt wird um aufgetretene Trends abzuflachen und mehr Fokus auf Saisonalität legen zu können. Dieses zu generierende Merkmal wird als regulierte calls, *reg_calls* bezeichnet.
4.  Ein indirekte Vorhersage aufgrund der Saisonaltität eines neuen kombinierten Merkmals aus *calls* und *n_sick*, die jedoch zuerst zu evaluieren ist. Das neue Merkmal wird *calls_sick* genannt.
5.  Wie in Punkt 4., aber wiederum unter Berücksichtigung einer jährlichen Steigerung von *n_duty* um aufgetretene Trends abzuflachen. Als Bezeichnung wird *reg_calls_sick* verwendet.

Die weitere Analyse konzentriert sich daher auf die ursprünglichen Merkmale *date*, *sby_need* und *calls* sowie auf die neu generierten Variablen.

Die in Punkt 4. beschriebene kombinierte Variable *calls_sick* aus *calls* und *n_sick* wird als Anrufe je krankgemeldetem/r Einsatzfahr:in verstanden und daher berechnet als

$$
calls\_sick_t =\frac{calls_t}{n\_sick_t}
$$

Die Werte von *n_duty* werden für die Analyse ab 01.01.2019 korrigiert und für die Merkmalsgenerierung "regulierter Calls" (*reg_calls*) und *reg_calls_sick* verwendet.

$$
reg\_calls_t = calls_t - n\_duty_t\ \ |\ \   n\_duty_t = 1700 + (year_t - 2016) * 100
$$ $$
reg\_calls\_sick_t = \frac{reg\_calls_t}{n\_sick_t}
$$

```{r}
#| echo: true
#| message: false
#| warning: false

ts_sby <- ts_sby %>%
  mutate(reg_calls = calls - (1700 + (year(date) - 2016) * 100),
         calls_sick = calls/n_sick,
         reg_calls_sick = reg_calls/n_sick) %>%
  select(-c("n_sick"))

ts_sby %>%
  GGally::ggpairs()

```

Um festzustellen welcher Ansatz möglicherweise erfolgversprechender ist, lohnt es sich die Variablen auf die vermeintliche Vorhersagbarkeit ihrer Saisonalität hin zu überprüfen. @hyndman_forecasting_2021 verweist hierbei auf die Spektrale Entropy (Shannon) einer Zeitreihe, die einen Wert zwischen 0 und 1 ausgibt. Je niedriger der Wert, desto stärker ist die Saisonalität und der Trend der Zeitreihe.

```{r}
#| echo: true
#| message: false
#| warning: false

ts_sby %>%
  select(-c("n_duty")) %>%
  features_all(feat_spectral)
```

Interessanterweise, ist trotz einer augenscheinlich gut erkennbaren Saisonalität der Entropie-Wert durchgehend relativ hoch. Am ehesten scheint sich an dieser Stelle das unregulierte Merkmal der Notfallanrufe (*calls*) für eine saisonal-bedingte Vorhersage zu eignen. Dieses Merkmal scheint annähernd normalverteilt zu sein und die Korrelation zur Zielvariablen *sby_need* liegt nur leicht unter dem regulierten Wert *reg_calls*. *calls_sick* und *reg_calls_sick* schneiden bei der Betrachtung der letzten beiden Faktoren deutlich schlechter ab.

Der Autokorrelationsplot der Variablen *calls* soll weiteren Aufschluss über dieses Merkmal geben. Hierfür werden 93 lags, also etwa drei Monate betrachtet.

```{r}
#| echo: true
#| message: false
#| warning: false

ts_sby %>% 
  ACF(y = calls, lag_max = 93) %>%
  autoplot()
```

Die höhere Autokorrelation in den niedrigen "lags", die im Verlauf abnimmt, zeigt, dass die Daten einem Trend unterliegen. Die "kleinen" Peaks bei 7, 14, 21, etc. zeigen eine leichte wochenweise Saisonalität, der etwas höhere bei 28 könnte auch auf eine monatliche Saisonalität hindeuten. Ab läg 63 nimmt der Autokorrelationswert schneller ab

Die Autokorrelation der Zielvariable (s.u.) zeigt im Vergleich dazu ebenso die wöchentlichen Peeks, jedoch eine viel schnellere Abnahme der Korrelation zu Beginn des Plots und damit einen weniger stark ausgeprägten Trend. Ab lag 63 wird die Autokorrelation der Zielvariablen mehr oder weniger unbrauchbar.


```{r}
#| echo: true
#| message: false
#| warning: false

ts_sby %>% 
  ACF(y = sby_need, lag_max = 93) %>%
  autoplot()
```



# Verteilung relevanter Merkmale

Die Verteilung der Zielvariablen und des möglichen Prädiktors gibt Auschluss, bzw. einen Überblick über die zu erwartenden Werte. Es werden die Zielvariable und das Merkmal *calls* verglichen.

```{r}
ggplot() + 
  geom_density(data = ts_sby, aes(x = log(sby_need + 1), fill = "red")) +
  geom_density(data = ts_sby, aes(x = log(calls), fill = "blue"))
```

bewertung

moving average um wochen saisonalität zu glätten

```{r}
#| echo: true
#| message: false
#| warning: false

ts_sby <- ts_sby %>%
  mutate(
    MA8 = slider::slide_dbl(calls, mean,
                            .before = 3, .after = 4,
                            .complete = TRUE),
    MA2_8 = slider::slide_dbl(MA8, mean,
                              .before = 1, .after = 0,
                              .complete = TRUE)
        ) 

p <- ts_sby %>%
  gg_season(MA2_8, period = "1y")

ggplotly(p)
```

am moving average von calls gut erkennbar, 2 verbleibende saisonalitäten monatlich und jährlich, starker trend vor allem zu beginn 2019

```{r}
#| echo: true
#| message: false
#| warning: false
#| 
ts_sby %>%
  features(MA2_8,feat_spectral)
```

zielvariable

```{r}
#| echo: true
#| message: false
#| warning: false

p <- ts_sby %>%
  gg_season(sby_need, period = "1y") +
  geom_smooth(level = 0.99)

ggplotly(p)
```

Die Zeilvaribale *sby_need* zeichnet sich in dem Plot durch wiederkehrende, plötzliche Anstiege und eine anschließende Rückkehr zum Wert 0 aus. Diese Peaks scheinen schon ein Muster aufzuweisen, sind jedoch im Jahr 2019 deutlich stärker ausgeprägt und zeigen auch im Vergleich zwischen den Jahren immer wieder offsets zu einander. Auffallend sind vor allem auch der, fast durchgehend niedrige Bedarf jeweils von November bis Anfang März.
Die smooth-curve bestätigt die höheren Werte von 2019, deckt aber, auch mit dem dargestelltenk 0.99 confidence level, die Peeks die ab. Die explizite Vorgabe "immer ausreichend" Bereitschaftspersonal vorzusehen" wird dadurch erschwert. 

moving quantile

```{r}
#| echo: true
#| message: false
#| warning: false

ts_sby <- ts_sby %>%
  mutate(
    MQ7 = slider::slide_dbl(sby_need, 
                            ~ quantile(x = .x,
                                       probs = 0.99),
                            .before = 3, .after = 3,
                            .complete = TRUE))  

p <- ts_sby %>%
  gg_season(MQ7, period = "1y") +
  geom_smooth(level = 0.99, se = FALSE)

ggplotly(p)
```

## Decomposition

```{r}
#| echo: true
#| message: false
#| warning: false


ts_sby %>%
  filter(!is.na(MA2_8)) %>%
  model(
    STL(MA2_8 ~ 
          trend(window = 365) +
          season(period = "1 year", window = 540) + 
          season(period = "1 month", window = 61))) %>%
  components() %>%
  autoplot()
```

Interpretation sieht gut aus. explorative analyse scheint sich in der decomposition zu bewahrheiten

residuals

# Untersuchung der linearen Korrelation zur Zielvariablen

```{r}
#| message: false
#| warning: false
#| include: false

require(ggpubr)

```


```{r}
#| echo: true
#| message: false
#| warning: false

p <- ggplot(ts_sby, 
            aes(x = calls,
                y = sby_need,
                colour = as.factor(year(date))
                )) +
  geom_point()

ggplotly(p)
```
Die Linearität der Korrelation ist gut ersichttlich. Ebenso gut ersichtlich ist jedoch, dass diese stark vom Jahr der Daten abhängig ist. Nachdem 2018 und 2019 genauso wie bei dem Merkmal *n_duty* in ihrer Ausprägung gleich zu sehen sind, ist anzunehmen, dass hier ebenso eine Abhängigkeit zu n_duty vorliegt. Das war auch im Korrelationsplot daran zu erkennen, dass die Abstände zwischen den "drei Linearzusammenhängen" in der Variablen *reg_calls* (also durch *n_duty* modifizierte *calls*) enger beieinander lagen, aber noch nicht auf einer Linie. Um diesen Zusammenhängen in einem Modell und zukünftigen Trainings Rechnung zu tragen wird *n_duty* bei dem linearen Modell berücksichtigt werden müssen. Die Abstände im augenscheinlichen "Intercept" betragen zwischen den Jahren jeweils etwa 500 (2016: ~8.000 *calls*, 2017: ~8.500 *calls*, 2018 und 2019: ~9.000 *calls*). Das ist jeweils das fünffache des Anstiegs in *n_duty*.

Wurden weniger Anrufe als der jeweilige "Intercept" getätigt wurde auch kein Bereitschaftspersonal aktiviert. Auch das wird in einem linearen Modell zu berücksichtigen sein.

Die nachfolgende Grafik in dieser explorativen Analyse versucht auf Basis dieser Annahmen eine einfache Linearität herzustellen.


```{r}
#| echo: true
#| message: false
#| warning: false

# Differenz der aktuellen n_duty zum Basiswert von 2016
ts_sby$diff_nduty <- ts_sby$n_duty - 1700

# Beobachteter Faktor für diese Differenz in der o.a. Korrelation
faktor <- 5

# Initialwert, ab wievielen Anrufen Bereitschaftspersonal zu aktivieren war
initial <- 8150

ggplot(ts_sby, 
       aes(x = pmax(0,calls - (diff_nduty * faktor) - initial),
           y = sby_need
           )) +
         geom_point() +
  stat_smooth(method = "lm", se = TRUE) +
  stat_regline_equation(label.x.npc = "center")

```
Das Modifizieren der Werte auf diese Weise scheint erfolgreich, hier ist die Differenzierung nach Jahren somit nicht mehr notwendig. Der abzuziehende Initialwert wie im o.a. Code beschrieben lieferte nach einigen Versuchen bei 8.150 eine gute Lineargleichung mit einem niedrigen aber positiven Intercept. 

*n_duty* in ein Modell einzubeziehen sollte keiner weiteren Vorhersage bedürfen, da dieser Wert im Vorhinein bekannt ist. 

# Fazit

Der in der Merkmalsübersicht angesprochene zweite Ansatz zur Vorhersage von *sby_need* scheint aufgrund der explorativen Analyse am vielversprechensten. Bei diesem Ansatz wurde eine indirekte Vorhersage aufgrund der Saisonalität des Merkmals *calls* und der, ab einem gewissen Wert, nahezu linear anzunehmenden Korrelation mit *sby_need* untersucht, wobei letztere jedoch "drei Liniaritäten" zeigt und  wahrscheinlich durch *n_duty* beeinflusst ist.

Die Qualität dieses Ansatzes wird in der Modellerstellung geprüft. Es ist jedoch davon auszugehen, dass die lineare Korrelation von *sby_need* und *calls*, sowie die Saisonalität von *calls* auch im Baseline-Modell niederschlag finden.

# Speichern aufbereiteter Daten

```{r}
#| echo: true
#| message: false
#| warning: false

save(ts_sby, file = "../00_sample_data/02_processed/data_explorative.rda")
```

# Literaturverzeichnis
